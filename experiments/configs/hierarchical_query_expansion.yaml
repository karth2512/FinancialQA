name: "hierarchical_with_query_expansion"
description: "Query expansion + hierarchical + LLM reranking for maximum recall and precision"
run_id: "exp-hierarchical-qe-001"
pipeline_type: "query_expansion"  # Uses QueryExpansionRAG

retrieval_config:
  strategy: "hierarchical"
  top_k: 15  # Retrieve more initially for reranking

  # Hierarchical config
  hierarchical_chunk_sizes: [2048, 512, 128]
  hierarchical_chunk_overlap: 20
  hierarchical_merge_threshold: 0.5

  # Embedding config
  embedding_model: "all-MiniLM-L6-v2"

  # Reranking configuration
  enable_reranking: true
  rerank_top_k: 10  # Filter to top 10 after reranking

llm_configs:
  expander:
    provider: "openai"
    model: "gpt-4o-mini"
    temperature: 0.7  # Diverse query variants
    max_tokens: 256
    api_key_env_var: "OPENAI_API_KEY"

  generator:
    provider: "openai"
    model: "gpt-4o-mini"
    temperature: 0.0
    max_tokens: 512
    api_key_env_var: "OPENAI_API_KEY"

  reranker:
    provider: "openai"
    model: "gpt-4o-mini"
    temperature: 0.0
    max_tokens: 1024
    api_key_env_var: "OPENAI_API_KEY"

hyperparameters:
  num_expanded_queries: 3  # Original + 3 variants

langfuse_dataset_name: "financial_qa_benchmark_v1"
enable_item_evaluators: true
item_evaluator_names: ["token_f1", "semantic_similarity", "retrieval_precision", "retrieval_recall"]
run_evaluator_names: ["average_accuracy", "aggregate_retrieval_metrics"]
