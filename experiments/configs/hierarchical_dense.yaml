name: "hierarchical_dense_baseline"
description: "Hierarchical chunking with dense embeddings and auto-merging"
run_id: "exp-hierarchical-001"
pipeline_type: "baseline"

retrieval_config:
  strategy: "hierarchical"
  top_k: 5

  # Hierarchical parameters
  hierarchical_chunk_sizes: [2048, 512, 128]  # 3-level hierarchy
  hierarchical_chunk_overlap: 20              # Token overlap
  hierarchical_merge_threshold: 0.5           # 50% siblings triggers merge

  # Embedding model (used by LlamaIndex)
  embedding_model: "all-MiniLM-L6-v2"

llm_configs:
  generator:
    provider: "anthropic"
    model: "claude-3-5-haiku-20241022"
    temperature: 0.0
    max_tokens: 512
    api_key_env_var: "ANTHROPIC_API_KEY"

langfuse_dataset_name: "financial_qa_benchmark_v1"
enable_item_evaluators: true
item_evaluator_names: ["token_f1", "semantic_similarity", "retrieval_precision", "retrieval_recall"]
run_evaluator_names: ["average_accuracy", "aggregate_retrieval_metrics"]
